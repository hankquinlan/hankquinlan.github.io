---
layout: post
title:  "Data Science Festival Live 2021"
date:   2021-11-27 09:00:00 +0000
categories: Data Science
permalink: /:title
---

<style>
.heading1 {
    color: red;
    font-weight:700;
    font-size: 35px;
}
.heading2 {
    color: blue;
    font-weight:700;
    font-size: 30px;
}
.heading3 {
    color: green;
    font-weight:700;
    font-size: 30px;
}
</style>
Introduction
============
It was great to get back to an IRL conference after nearly two years. The Data Science Festival Live 2021 took place at Code Node, South Place just off Moorgate in London on 27th November 2021. It was equally wonderful to be back at Skills Matter for the first since its resurrection.

In what follows, the descriptions are from the talks I personally went to, following my particular interests.

The full agenda is attached at the bottom of this post.

Robots Everywhere - The Role of Data Science and Automation in the Creative Industry by Magda Woods, Waive
==========================================================================================================

In this talks Magda talks about how automation has removed the need for repetitive, routine and boring tasks to be done manually, for example the collection of news feeds, a task that that used a cut and paste one. This allows content creators to concentrate on what really matters to them and frees up resources that can be better deployed.

Magda also pursued the theme of "the next big breakthrough in Artificial Intelligence will be to do with language". I thought big breakthroughs were already being made in NLP, but maybe Magda was alluding to a game changing breakthrough.


Data Quality with LV=’s Input–Checker by Ned Webster, LV=
=========================================================

Ned talked about Input Checker, a python package for checking if data stored in pandas data frames meets a number of prerequisites. 

Input Checker is one of three projects that LV has opened sourced at https://github.com/lvgig, the others being tubular, a python package using transformers for pre-processing, and test-aide, package to support unit testing in data science projects.

Ned explored what we mean by data quality. He described some existing frameworks for checking data quality, notably Great Expectations,  a shared, open standard for data quality (https://greatexpectations.io/). He also described an enabler for Input Checker, Marshmallow, an ORM/ODM/framework-agnostic library for converting complex datatypes, such as objects, to and from native Python datatypes.

Input Checker enables users to compare a given data frame against a benchmark data frame. This is similar to the Golden Master concept, which is a saved copy of the output a program generates.


Input Checker checks the following to ensure the mutated data frame is the same as the original in the following respects:

- Nulls
- Dtypes
- Categorical values
- Numerical values
- Datetime values

This is a very useful tool when reorganising the code.

The realities of building domain-specific language models for production by Matt Harding & Stanimir Vichev, London Stock Exchange Group (LSEG)
==============================================================================================================================================

LSEG Labs have built a set of domain-specific language models, based on Google’s BERT architecture, using LSEG’s proprietary financial data. 

The talk describes taking these models from inception to production describing all the problems encountered on the way, from testing the waters to convicing decision makers that the project was worth investing in. NLP was fundamental in this endeavour.

LSEG uses a Financial News Language model, derived through the pre-processing of financial news from the Reuters News Archive (RNA). BERT-RNA as it is known, is pre-trained on top BERT base of using the RNA. The archive contains all Reuters articles published between 1996 and 2019.

Training took place on GCP Preemptible TPUs and running inference via AWS Batch Transform. The tech stack is made up of Python, SpaCy, Regex, S3 and Athena,  which works directly with data stored in S3 using standard SQL.

Matt and Stan then discussed how the model was benchmarked using a downstream classification task. 

They went onto discuss their plans for future, including experimenting with different BERT architectures, introducing MLOps, using a feauture store for inference training, and using other financial news datasets.

In conclusion they discussed the pros and cons of different ways of providing the models to their customers.

A/B testing: Setting up for success & choosing the right Statistical Framework by Benjamin Pettit, Cleo
=======================================================================================================


Using hybrid recommender system to personalise Financial Times push notifications by Adam Gajtkowski, Finacial Times
====================================================================================================================

Connecting the Dots: Harnessing the Power of Graphs & ML by Ebru Cucen, Opencredo 
=================================================================================

Fighting bad information with AI by Alex Joseph Full Fact
=========================================================

Vigorous communication as the key ingredient of a successful data science career by Roberto Medri, Meta
=======================================================================================================

[DSF_Schedule_A4Sheet_v8.pdf](https://github.com/mbateman/mbateman.github.io/files/8179259/DSF_Schedule_A4Sheet_v8.pdf)
